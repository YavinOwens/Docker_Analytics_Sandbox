{"ast":null,"code":"/*\n * MinIO Javascript Library for Amazon S3 Compatible Cloud Storage, (C) 2016 MinIO, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as Crypto from \"crypto\";\nimport { Transform } from \"stream\";\nimport * as querystring from 'query-string';\nimport { getVersionId, sanitizeETag } from \"./internal/helper.mjs\";\n\n// We extend Transform because Writable does not implement ._flush().\nexport class ObjectUploader extends Transform {\n  constructor(client, bucketName, objectName, partSize, metaData, callback) {\n    super();\n    this.emptyStream = true;\n    this.client = client;\n    this.bucketName = bucketName;\n    this.objectName = objectName;\n    // The size of each multipart, chunked by BlockStream2.\n    this.partSize = partSize;\n    // This is the metadata for the object.\n    this.metaData = metaData;\n\n    // Call like: callback(error, {etag, versionId}).\n    this.callback = callback;\n\n    // We need to keep track of what number chunk/part we're on. This increments\n    // each time _write() is called. Starts with 1, not 0.\n    this.partNumber = 1;\n\n    // A list of the previously uploaded chunks, for resuming a file upload. This\n    // will be null if we aren't resuming an upload.\n    this.oldParts = null;\n\n    // Keep track of the etags for aggregating the chunks together later. Each\n    // etag represents a single chunk of the file.\n    this.etags = [];\n\n    // This is for the multipart upload request — if null, we're either not initiated\n    // yet or we're flushing in one packet.\n    this.id = null;\n\n    // Handle errors.\n    this.on('error', err => {\n      callback(err);\n    });\n  }\n  _transform(chunk, encoding, callback) {\n    this.emptyStream = false;\n    let method = 'PUT';\n    let headers = {\n      'Content-Length': chunk.length\n    };\n    let md5digest = '';\n\n    // Calculate and set Content-MD5 header if SHA256 is not set.\n    // This will happen only when there is a secure connection to the s3 server.\n    if (!this.client.enableSHA256) {\n      md5digest = Crypto.createHash('md5').update(chunk).digest();\n      headers['Content-MD5'] = md5digest.toString('base64');\n    }\n    // We can flush the object in one packet if it fits in one chunk. This is true\n    // if the chunk size is smaller than the part size, signifying the end of the\n    // stream.\n    if (this.partNumber == 1 && chunk.length < this.partSize) {\n      // PUT the chunk in a single request — use an empty query.\n      let options = {\n        method,\n        // Set user metadata as this is not a multipart upload\n        headers: Object.assign({}, this.metaData, headers),\n        query: '',\n        bucketName: this.bucketName,\n        objectName: this.objectName\n      };\n      this.client.makeRequest(options, chunk, [200], '', true, (err, response) => {\n        if (err) {\n          return callback(err);\n        }\n        let result = {\n          etag: sanitizeETag(response.headers.etag),\n          versionId: getVersionId(response.headers)\n        };\n        // Ignore the 'data' event so that the stream closes. (nodejs stream requirement)\n        response.on('data', () => {});\n\n        // Give the etag back, we're done!\n\n        process.nextTick(() => {\n          this.callback(null, result);\n        });\n\n        // Because we're sure the stream has ended, allow it to flush and end.\n        callback();\n      });\n      return;\n    }\n\n    // If we aren't flushing in one packet, we need to initiate the multipart upload,\n    // if it hasn't already been done. The write will be buffered until the upload has been\n    // initiated.\n    if (this.id === null) {\n      this.once('ready', () => {\n        this._transform(chunk, encoding, callback);\n      });\n\n      // Check for an incomplete previous upload.\n      this.client.findUploadId(this.bucketName, this.objectName, (err, id) => {\n        if (err) {\n          return this.emit('error', err);\n        }\n\n        // If no upload ID exists, initiate a new one.\n        if (!id) {\n          this.client.initiateNewMultipartUpload(this.bucketName, this.objectName, this.metaData).then(id => {\n            this.id = id;\n\n            // We are now ready to accept new chunks — this will flush the buffered chunk.\n            this.emit('ready');\n          }, err => callback(err));\n          return;\n        }\n        this.id = id;\n\n        // Retrieve the pre-uploaded parts, if we need to resume the upload.\n        this.client.listParts(this.bucketName, this.objectName, id).then(etags => {\n          // It is possible for no parts to be already uploaded.\n          if (!etags) {\n            etags = [];\n          }\n\n          // oldParts will become an object, allowing oldParts[partNumber].etag\n          this.oldParts = etags.reduce(function (prev, item) {\n            if (!prev[item.part]) {\n              prev[item.part] = item;\n            }\n            return prev;\n          }, {});\n          this.emit('ready');\n        }, err => {\n          return this.emit('error', err);\n        });\n      });\n      return;\n    }\n\n    // Continue uploading various parts if we have initiated multipart upload.\n    let partNumber = this.partNumber++;\n\n    // Check to see if we've already uploaded this chunk. If the hash sums match,\n    // we can skip to the next chunk.\n    if (this.oldParts) {\n      let oldPart = this.oldParts[partNumber];\n\n      // Calulcate the md5 hash, if it has not already been calculated.\n      if (!md5digest) {\n        md5digest = Crypto.createHash('md5').update(chunk).digest();\n      }\n      if (oldPart && md5digest.toString('hex') === oldPart.etag) {\n        // The md5 matches, the chunk has already been uploaded.\n        this.etags.push({\n          part: partNumber,\n          etag: oldPart.etag\n        });\n        callback();\n        return;\n      }\n    }\n\n    // Write the chunk with an uploader.\n    let query = querystring.stringify({\n      partNumber: partNumber,\n      uploadId: this.id\n    });\n    let options = {\n      method,\n      query,\n      headers,\n      bucketName: this.bucketName,\n      objectName: this.objectName\n    };\n    this.client.makeRequest(options, chunk, [200], '', true, (err, response) => {\n      if (err) {\n        return callback(err);\n      }\n\n      // In order to aggregate the parts together, we need to collect the etags.\n      let etag = response.headers.etag;\n      if (etag) {\n        etag = etag.replace(/^\"/, '').replace(/\"$/, '');\n      }\n      this.etags.push({\n        part: partNumber,\n        etag\n      });\n\n      // Ignore the 'data' event so that the stream closes. (nodejs stream requirement)\n      response.on('data', () => {});\n\n      // We're ready for the next chunk.\n      callback();\n    });\n  }\n  _flush(callback) {\n    if (this.emptyStream) {\n      let method = 'PUT';\n      let headers = Object.assign({}, this.metaData, {\n        'Content-Length': 0\n      });\n      let options = {\n        method,\n        headers,\n        query: '',\n        bucketName: this.bucketName,\n        objectName: this.objectName\n      };\n      this.client.makeRequest(options, '', [200], '', true, (err, response) => {\n        if (err) {\n          return callback(err);\n        }\n        let result = {\n          etag: sanitizeETag(response.headers.etag),\n          versionId: getVersionId(response.headers)\n        };\n\n        // Ignore the 'data' event so that the stream closes. (nodejs stream requirement)\n        response.on('data', () => {});\n\n        // Give the etag back, we're done!\n        process.nextTick(() => {\n          this.callback(null, result);\n        });\n\n        // Because we're sure the stream has ended, allow it to flush and end.\n        callback();\n      });\n      return;\n    }\n    // If it has been uploaded in a single packet, we don't have to do anything.\n    if (this.id === null) {\n      return;\n    }\n\n    // This is called when all of the chunks uploaded successfully, thus\n    // completing the multipart upload.\n    this.client.completeMultipartUpload(this.bucketName, this.objectName, this.id, this.etags, (err, etag) => {\n      if (err) {\n        return callback(err);\n      }\n\n      // Call our callback on the next tick to allow the streams infrastructure\n      // to finish what its doing before we continue.\n      process.nextTick(() => {\n        this.callback(null, etag);\n      });\n      callback();\n    });\n  }\n}\n\n// deprecated default export, please use named exports.\n// keep for backward compatibility.\n// eslint-disable-next-line import/no-default-export\nexport default ObjectUploader;","map":{"version":3,"names":["Crypto","Transform","querystring","getVersionId","sanitizeETag","ObjectUploader","constructor","client","bucketName","objectName","partSize","metaData","callback","emptyStream","partNumber","oldParts","etags","id","on","err","_transform","chunk","encoding","method","headers","length","md5digest","enableSHA256","createHash","update","digest","toString","options","Object","assign","query","makeRequest","response","result","etag","versionId","process","nextTick","once","findUploadId","emit","initiateNewMultipartUpload","then","listParts","reduce","prev","item","part","oldPart","push","stringify","uploadId","replace","_flush","completeMultipartUpload"],"sources":["/Users/admin/Documents/analytical_engineering/Docker_Analytics_Sandbox/src/react-app/node_modules/minio/dist/esm/object-uploader.js"],"sourcesContent":["/*\n * MinIO Javascript Library for Amazon S3 Compatible Cloud Storage, (C) 2016 MinIO, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as Crypto from 'node:crypto'\nimport { Transform } from 'node:stream'\n\nimport * as querystring from 'query-string'\n\nimport { getVersionId, sanitizeETag } from './internal/helper.ts'\n\n// We extend Transform because Writable does not implement ._flush().\nexport class ObjectUploader extends Transform {\n  constructor(client, bucketName, objectName, partSize, metaData, callback) {\n    super()\n    this.emptyStream = true\n    this.client = client\n    this.bucketName = bucketName\n    this.objectName = objectName\n    // The size of each multipart, chunked by BlockStream2.\n    this.partSize = partSize\n    // This is the metadata for the object.\n    this.metaData = metaData\n\n    // Call like: callback(error, {etag, versionId}).\n    this.callback = callback\n\n    // We need to keep track of what number chunk/part we're on. This increments\n    // each time _write() is called. Starts with 1, not 0.\n    this.partNumber = 1\n\n    // A list of the previously uploaded chunks, for resuming a file upload. This\n    // will be null if we aren't resuming an upload.\n    this.oldParts = null\n\n    // Keep track of the etags for aggregating the chunks together later. Each\n    // etag represents a single chunk of the file.\n    this.etags = []\n\n    // This is for the multipart upload request — if null, we're either not initiated\n    // yet or we're flushing in one packet.\n    this.id = null\n\n    // Handle errors.\n    this.on('error', (err) => {\n      callback(err)\n    })\n  }\n\n  _transform(chunk, encoding, callback) {\n    this.emptyStream = false\n    let method = 'PUT'\n    let headers = { 'Content-Length': chunk.length }\n    let md5digest = ''\n\n    // Calculate and set Content-MD5 header if SHA256 is not set.\n    // This will happen only when there is a secure connection to the s3 server.\n    if (!this.client.enableSHA256) {\n      md5digest = Crypto.createHash('md5').update(chunk).digest()\n      headers['Content-MD5'] = md5digest.toString('base64')\n    }\n    // We can flush the object in one packet if it fits in one chunk. This is true\n    // if the chunk size is smaller than the part size, signifying the end of the\n    // stream.\n    if (this.partNumber == 1 && chunk.length < this.partSize) {\n      // PUT the chunk in a single request — use an empty query.\n      let options = {\n        method,\n        // Set user metadata as this is not a multipart upload\n        headers: Object.assign({}, this.metaData, headers),\n        query: '',\n        bucketName: this.bucketName,\n        objectName: this.objectName,\n      }\n\n      this.client.makeRequest(options, chunk, [200], '', true, (err, response) => {\n        if (err) {\n          return callback(err)\n        }\n        let result = {\n          etag: sanitizeETag(response.headers.etag),\n          versionId: getVersionId(response.headers),\n        }\n        // Ignore the 'data' event so that the stream closes. (nodejs stream requirement)\n        response.on('data', () => {})\n\n        // Give the etag back, we're done!\n\n        process.nextTick(() => {\n          this.callback(null, result)\n        })\n\n        // Because we're sure the stream has ended, allow it to flush and end.\n        callback()\n      })\n\n      return\n    }\n\n    // If we aren't flushing in one packet, we need to initiate the multipart upload,\n    // if it hasn't already been done. The write will be buffered until the upload has been\n    // initiated.\n    if (this.id === null) {\n      this.once('ready', () => {\n        this._transform(chunk, encoding, callback)\n      })\n\n      // Check for an incomplete previous upload.\n      this.client.findUploadId(this.bucketName, this.objectName, (err, id) => {\n        if (err) {\n          return this.emit('error', err)\n        }\n\n        // If no upload ID exists, initiate a new one.\n        if (!id) {\n          this.client.initiateNewMultipartUpload(this.bucketName, this.objectName, this.metaData).then(\n            (id) => {\n              this.id = id\n\n              // We are now ready to accept new chunks — this will flush the buffered chunk.\n              this.emit('ready')\n            },\n            (err) => callback(err),\n          )\n\n          return\n        }\n\n        this.id = id\n\n        // Retrieve the pre-uploaded parts, if we need to resume the upload.\n        this.client.listParts(this.bucketName, this.objectName, id).then(\n          (etags) => {\n            // It is possible for no parts to be already uploaded.\n            if (!etags) {\n              etags = []\n            }\n\n            // oldParts will become an object, allowing oldParts[partNumber].etag\n            this.oldParts = etags.reduce(function (prev, item) {\n              if (!prev[item.part]) {\n                prev[item.part] = item\n              }\n              return prev\n            }, {})\n\n            this.emit('ready')\n          },\n          (err) => {\n            return this.emit('error', err)\n          },\n        )\n      })\n\n      return\n    }\n\n    // Continue uploading various parts if we have initiated multipart upload.\n    let partNumber = this.partNumber++\n\n    // Check to see if we've already uploaded this chunk. If the hash sums match,\n    // we can skip to the next chunk.\n    if (this.oldParts) {\n      let oldPart = this.oldParts[partNumber]\n\n      // Calulcate the md5 hash, if it has not already been calculated.\n      if (!md5digest) {\n        md5digest = Crypto.createHash('md5').update(chunk).digest()\n      }\n\n      if (oldPart && md5digest.toString('hex') === oldPart.etag) {\n        // The md5 matches, the chunk has already been uploaded.\n        this.etags.push({ part: partNumber, etag: oldPart.etag })\n\n        callback()\n        return\n      }\n    }\n\n    // Write the chunk with an uploader.\n    let query = querystring.stringify({\n      partNumber: partNumber,\n      uploadId: this.id,\n    })\n\n    let options = {\n      method,\n      query,\n      headers,\n      bucketName: this.bucketName,\n      objectName: this.objectName,\n    }\n\n    this.client.makeRequest(options, chunk, [200], '', true, (err, response) => {\n      if (err) {\n        return callback(err)\n      }\n\n      // In order to aggregate the parts together, we need to collect the etags.\n      let etag = response.headers.etag\n      if (etag) {\n        etag = etag.replace(/^\"/, '').replace(/\"$/, '')\n      }\n\n      this.etags.push({ part: partNumber, etag })\n\n      // Ignore the 'data' event so that the stream closes. (nodejs stream requirement)\n      response.on('data', () => {})\n\n      // We're ready for the next chunk.\n      callback()\n    })\n  }\n\n  _flush(callback) {\n    if (this.emptyStream) {\n      let method = 'PUT'\n      let headers = Object.assign({}, this.metaData, { 'Content-Length': 0 })\n      let options = {\n        method,\n        headers,\n        query: '',\n        bucketName: this.bucketName,\n        objectName: this.objectName,\n      }\n\n      this.client.makeRequest(options, '', [200], '', true, (err, response) => {\n        if (err) {\n          return callback(err)\n        }\n\n        let result = {\n          etag: sanitizeETag(response.headers.etag),\n          versionId: getVersionId(response.headers),\n        }\n\n        // Ignore the 'data' event so that the stream closes. (nodejs stream requirement)\n        response.on('data', () => {})\n\n        // Give the etag back, we're done!\n        process.nextTick(() => {\n          this.callback(null, result)\n        })\n\n        // Because we're sure the stream has ended, allow it to flush and end.\n        callback()\n      })\n\n      return\n    }\n    // If it has been uploaded in a single packet, we don't have to do anything.\n    if (this.id === null) {\n      return\n    }\n\n    // This is called when all of the chunks uploaded successfully, thus\n    // completing the multipart upload.\n    this.client.completeMultipartUpload(this.bucketName, this.objectName, this.id, this.etags, (err, etag) => {\n      if (err) {\n        return callback(err)\n      }\n\n      // Call our callback on the next tick to allow the streams infrastructure\n      // to finish what its doing before we continue.\n      process.nextTick(() => {\n        this.callback(null, etag)\n      })\n\n      callback()\n    })\n  }\n}\n\n// deprecated default export, please use named exports.\n// keep for backward compatibility.\n// eslint-disable-next-line import/no-default-export\nexport default ObjectUploader\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,OAAO,KAAKA,MAAM;AAClB,SAASC,SAAS;AAElB,OAAO,KAAKC,WAAW,MAAM,cAAc;AAE3C,SAASC,YAAY,EAAEC,YAAY,QAAQ,uBAAsB;;AAEjE;AACA,OAAO,MAAMC,cAAc,SAASJ,SAAS,CAAC;EAC5CK,WAAWA,CAACC,MAAM,EAAEC,UAAU,EAAEC,UAAU,EAAEC,QAAQ,EAAEC,QAAQ,EAAEC,QAAQ,EAAE;IACxE,KAAK,CAAC,CAAC;IACP,IAAI,CAACC,WAAW,GAAG,IAAI;IACvB,IAAI,CAACN,MAAM,GAAGA,MAAM;IACpB,IAAI,CAACC,UAAU,GAAGA,UAAU;IAC5B,IAAI,CAACC,UAAU,GAAGA,UAAU;IAC5B;IACA,IAAI,CAACC,QAAQ,GAAGA,QAAQ;IACxB;IACA,IAAI,CAACC,QAAQ,GAAGA,QAAQ;;IAExB;IACA,IAAI,CAACC,QAAQ,GAAGA,QAAQ;;IAExB;IACA;IACA,IAAI,CAACE,UAAU,GAAG,CAAC;;IAEnB;IACA;IACA,IAAI,CAACC,QAAQ,GAAG,IAAI;;IAEpB;IACA;IACA,IAAI,CAACC,KAAK,GAAG,EAAE;;IAEf;IACA;IACA,IAAI,CAACC,EAAE,GAAG,IAAI;;IAEd;IACA,IAAI,CAACC,EAAE,CAAC,OAAO,EAAGC,GAAG,IAAK;MACxBP,QAAQ,CAACO,GAAG,CAAC;IACf,CAAC,CAAC;EACJ;EAEAC,UAAUA,CAACC,KAAK,EAAEC,QAAQ,EAAEV,QAAQ,EAAE;IACpC,IAAI,CAACC,WAAW,GAAG,KAAK;IACxB,IAAIU,MAAM,GAAG,KAAK;IAClB,IAAIC,OAAO,GAAG;MAAE,gBAAgB,EAAEH,KAAK,CAACI;IAAO,CAAC;IAChD,IAAIC,SAAS,GAAG,EAAE;;IAElB;IACA;IACA,IAAI,CAAC,IAAI,CAACnB,MAAM,CAACoB,YAAY,EAAE;MAC7BD,SAAS,GAAG1B,MAAM,CAAC4B,UAAU,CAAC,KAAK,CAAC,CAACC,MAAM,CAACR,KAAK,CAAC,CAACS,MAAM,CAAC,CAAC;MAC3DN,OAAO,CAAC,aAAa,CAAC,GAAGE,SAAS,CAACK,QAAQ,CAAC,QAAQ,CAAC;IACvD;IACA;IACA;IACA;IACA,IAAI,IAAI,CAACjB,UAAU,IAAI,CAAC,IAAIO,KAAK,CAACI,MAAM,GAAG,IAAI,CAACf,QAAQ,EAAE;MACxD;MACA,IAAIsB,OAAO,GAAG;QACZT,MAAM;QACN;QACAC,OAAO,EAAES,MAAM,CAACC,MAAM,CAAC,CAAC,CAAC,EAAE,IAAI,CAACvB,QAAQ,EAAEa,OAAO,CAAC;QAClDW,KAAK,EAAE,EAAE;QACT3B,UAAU,EAAE,IAAI,CAACA,UAAU;QAC3BC,UAAU,EAAE,IAAI,CAACA;MACnB,CAAC;MAED,IAAI,CAACF,MAAM,CAAC6B,WAAW,CAACJ,OAAO,EAAEX,KAAK,EAAE,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,IAAI,EAAE,CAACF,GAAG,EAAEkB,QAAQ,KAAK;QAC1E,IAAIlB,GAAG,EAAE;UACP,OAAOP,QAAQ,CAACO,GAAG,CAAC;QACtB;QACA,IAAImB,MAAM,GAAG;UACXC,IAAI,EAAEnC,YAAY,CAACiC,QAAQ,CAACb,OAAO,CAACe,IAAI,CAAC;UACzCC,SAAS,EAAErC,YAAY,CAACkC,QAAQ,CAACb,OAAO;QAC1C,CAAC;QACD;QACAa,QAAQ,CAACnB,EAAE,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;;QAE7B;;QAEAuB,OAAO,CAACC,QAAQ,CAAC,MAAM;UACrB,IAAI,CAAC9B,QAAQ,CAAC,IAAI,EAAE0B,MAAM,CAAC;QAC7B,CAAC,CAAC;;QAEF;QACA1B,QAAQ,CAAC,CAAC;MACZ,CAAC,CAAC;MAEF;IACF;;IAEA;IACA;IACA;IACA,IAAI,IAAI,CAACK,EAAE,KAAK,IAAI,EAAE;MACpB,IAAI,CAAC0B,IAAI,CAAC,OAAO,EAAE,MAAM;QACvB,IAAI,CAACvB,UAAU,CAACC,KAAK,EAAEC,QAAQ,EAAEV,QAAQ,CAAC;MAC5C,CAAC,CAAC;;MAEF;MACA,IAAI,CAACL,MAAM,CAACqC,YAAY,CAAC,IAAI,CAACpC,UAAU,EAAE,IAAI,CAACC,UAAU,EAAE,CAACU,GAAG,EAAEF,EAAE,KAAK;QACtE,IAAIE,GAAG,EAAE;UACP,OAAO,IAAI,CAAC0B,IAAI,CAAC,OAAO,EAAE1B,GAAG,CAAC;QAChC;;QAEA;QACA,IAAI,CAACF,EAAE,EAAE;UACP,IAAI,CAACV,MAAM,CAACuC,0BAA0B,CAAC,IAAI,CAACtC,UAAU,EAAE,IAAI,CAACC,UAAU,EAAE,IAAI,CAACE,QAAQ,CAAC,CAACoC,IAAI,CACzF9B,EAAE,IAAK;YACN,IAAI,CAACA,EAAE,GAAGA,EAAE;;YAEZ;YACA,IAAI,CAAC4B,IAAI,CAAC,OAAO,CAAC;UACpB,CAAC,EACA1B,GAAG,IAAKP,QAAQ,CAACO,GAAG,CACvB,CAAC;UAED;QACF;QAEA,IAAI,CAACF,EAAE,GAAGA,EAAE;;QAEZ;QACA,IAAI,CAACV,MAAM,CAACyC,SAAS,CAAC,IAAI,CAACxC,UAAU,EAAE,IAAI,CAACC,UAAU,EAAEQ,EAAE,CAAC,CAAC8B,IAAI,CAC7D/B,KAAK,IAAK;UACT;UACA,IAAI,CAACA,KAAK,EAAE;YACVA,KAAK,GAAG,EAAE;UACZ;;UAEA;UACA,IAAI,CAACD,QAAQ,GAAGC,KAAK,CAACiC,MAAM,CAAC,UAAUC,IAAI,EAAEC,IAAI,EAAE;YACjD,IAAI,CAACD,IAAI,CAACC,IAAI,CAACC,IAAI,CAAC,EAAE;cACpBF,IAAI,CAACC,IAAI,CAACC,IAAI,CAAC,GAAGD,IAAI;YACxB;YACA,OAAOD,IAAI;UACb,CAAC,EAAE,CAAC,CAAC,CAAC;UAEN,IAAI,CAACL,IAAI,CAAC,OAAO,CAAC;QACpB,CAAC,EACA1B,GAAG,IAAK;UACP,OAAO,IAAI,CAAC0B,IAAI,CAAC,OAAO,EAAE1B,GAAG,CAAC;QAChC,CACF,CAAC;MACH,CAAC,CAAC;MAEF;IACF;;IAEA;IACA,IAAIL,UAAU,GAAG,IAAI,CAACA,UAAU,EAAE;;IAElC;IACA;IACA,IAAI,IAAI,CAACC,QAAQ,EAAE;MACjB,IAAIsC,OAAO,GAAG,IAAI,CAACtC,QAAQ,CAACD,UAAU,CAAC;;MAEvC;MACA,IAAI,CAACY,SAAS,EAAE;QACdA,SAAS,GAAG1B,MAAM,CAAC4B,UAAU,CAAC,KAAK,CAAC,CAACC,MAAM,CAACR,KAAK,CAAC,CAACS,MAAM,CAAC,CAAC;MAC7D;MAEA,IAAIuB,OAAO,IAAI3B,SAAS,CAACK,QAAQ,CAAC,KAAK,CAAC,KAAKsB,OAAO,CAACd,IAAI,EAAE;QACzD;QACA,IAAI,CAACvB,KAAK,CAACsC,IAAI,CAAC;UAAEF,IAAI,EAAEtC,UAAU;UAAEyB,IAAI,EAAEc,OAAO,CAACd;QAAK,CAAC,CAAC;QAEzD3B,QAAQ,CAAC,CAAC;QACV;MACF;IACF;;IAEA;IACA,IAAIuB,KAAK,GAAGjC,WAAW,CAACqD,SAAS,CAAC;MAChCzC,UAAU,EAAEA,UAAU;MACtB0C,QAAQ,EAAE,IAAI,CAACvC;IACjB,CAAC,CAAC;IAEF,IAAIe,OAAO,GAAG;MACZT,MAAM;MACNY,KAAK;MACLX,OAAO;MACPhB,UAAU,EAAE,IAAI,CAACA,UAAU;MAC3BC,UAAU,EAAE,IAAI,CAACA;IACnB,CAAC;IAED,IAAI,CAACF,MAAM,CAAC6B,WAAW,CAACJ,OAAO,EAAEX,KAAK,EAAE,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,IAAI,EAAE,CAACF,GAAG,EAAEkB,QAAQ,KAAK;MAC1E,IAAIlB,GAAG,EAAE;QACP,OAAOP,QAAQ,CAACO,GAAG,CAAC;MACtB;;MAEA;MACA,IAAIoB,IAAI,GAAGF,QAAQ,CAACb,OAAO,CAACe,IAAI;MAChC,IAAIA,IAAI,EAAE;QACRA,IAAI,GAAGA,IAAI,CAACkB,OAAO,CAAC,IAAI,EAAE,EAAE,CAAC,CAACA,OAAO,CAAC,IAAI,EAAE,EAAE,CAAC;MACjD;MAEA,IAAI,CAACzC,KAAK,CAACsC,IAAI,CAAC;QAAEF,IAAI,EAAEtC,UAAU;QAAEyB;MAAK,CAAC,CAAC;;MAE3C;MACAF,QAAQ,CAACnB,EAAE,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;;MAE7B;MACAN,QAAQ,CAAC,CAAC;IACZ,CAAC,CAAC;EACJ;EAEA8C,MAAMA,CAAC9C,QAAQ,EAAE;IACf,IAAI,IAAI,CAACC,WAAW,EAAE;MACpB,IAAIU,MAAM,GAAG,KAAK;MAClB,IAAIC,OAAO,GAAGS,MAAM,CAACC,MAAM,CAAC,CAAC,CAAC,EAAE,IAAI,CAACvB,QAAQ,EAAE;QAAE,gBAAgB,EAAE;MAAE,CAAC,CAAC;MACvE,IAAIqB,OAAO,GAAG;QACZT,MAAM;QACNC,OAAO;QACPW,KAAK,EAAE,EAAE;QACT3B,UAAU,EAAE,IAAI,CAACA,UAAU;QAC3BC,UAAU,EAAE,IAAI,CAACA;MACnB,CAAC;MAED,IAAI,CAACF,MAAM,CAAC6B,WAAW,CAACJ,OAAO,EAAE,EAAE,EAAE,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,IAAI,EAAE,CAACb,GAAG,EAAEkB,QAAQ,KAAK;QACvE,IAAIlB,GAAG,EAAE;UACP,OAAOP,QAAQ,CAACO,GAAG,CAAC;QACtB;QAEA,IAAImB,MAAM,GAAG;UACXC,IAAI,EAAEnC,YAAY,CAACiC,QAAQ,CAACb,OAAO,CAACe,IAAI,CAAC;UACzCC,SAAS,EAAErC,YAAY,CAACkC,QAAQ,CAACb,OAAO;QAC1C,CAAC;;QAED;QACAa,QAAQ,CAACnB,EAAE,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;;QAE7B;QACAuB,OAAO,CAACC,QAAQ,CAAC,MAAM;UACrB,IAAI,CAAC9B,QAAQ,CAAC,IAAI,EAAE0B,MAAM,CAAC;QAC7B,CAAC,CAAC;;QAEF;QACA1B,QAAQ,CAAC,CAAC;MACZ,CAAC,CAAC;MAEF;IACF;IACA;IACA,IAAI,IAAI,CAACK,EAAE,KAAK,IAAI,EAAE;MACpB;IACF;;IAEA;IACA;IACA,IAAI,CAACV,MAAM,CAACoD,uBAAuB,CAAC,IAAI,CAACnD,UAAU,EAAE,IAAI,CAACC,UAAU,EAAE,IAAI,CAACQ,EAAE,EAAE,IAAI,CAACD,KAAK,EAAE,CAACG,GAAG,EAAEoB,IAAI,KAAK;MACxG,IAAIpB,GAAG,EAAE;QACP,OAAOP,QAAQ,CAACO,GAAG,CAAC;MACtB;;MAEA;MACA;MACAsB,OAAO,CAACC,QAAQ,CAAC,MAAM;QACrB,IAAI,CAAC9B,QAAQ,CAAC,IAAI,EAAE2B,IAAI,CAAC;MAC3B,CAAC,CAAC;MAEF3B,QAAQ,CAAC,CAAC;IACZ,CAAC,CAAC;EACJ;AACF;;AAEA;AACA;AACA;AACA,eAAeP,cAAc","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}