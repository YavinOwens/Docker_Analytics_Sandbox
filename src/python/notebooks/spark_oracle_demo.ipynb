{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "import os\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"OracleSparkIntegration\") \\\n",
        "    .config(\"spark.jars.packages\", \"com.oracle.database.jdbc:ojdbc8:19.3.0.0\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Oracle connection details\n",
        "oracle_host = os.getenv(\"ORACLE_HOST\", \"oracle\")\n",
        "oracle_port = os.getenv(\"ORACLE_PORT\", \"1521\")\n",
        "oracle_service = os.getenv(\"ORACLE_SERVICE\", \"FREE\")\n",
        "oracle_user = os.getenv(\"ORACLE_USER\", \"system\")\n",
        "oracle_password = os.getenv(\"ORACLE_PASSWORD\", \"oracle\")\n",
        "\n",
        "# JDBC URL for Oracle\n",
        "jdbc_url = f\"jdbc:oracle:thin:@{oracle_host}:{oracle_port}/{oracle_service}\"\n",
        "\n",
        "# Example 1: Read data from Oracle\n",
        "def read_from_oracle():\n",
        "    try:\n",
        "        # Read data from Oracle\n",
        "        df = spark.read \\\n",
        "            .format(\"jdbc\") \\\n",
        "            .option(\"url\", jdbc_url) \\\n",
        "            .option(\"user\", oracle_user) \\\n",
        "            .option(\"password\", oracle_password) \\\n",
        "            .option(\"driver\", \"oracle.jdbc.driver.OracleDriver\") \\\n",
        "            .option(\"query\", \"SELECT * FROM v$version\") \\\n",
        "            .load()\n",
        "        \n",
        "        print(\"Oracle Version:\")\n",
        "        df.show(truncate=False)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error reading from Oracle: {str(e)}\")\n",
        "\n",
        "# Example 2: Create a sample DataFrame and write to Oracle\n",
        "def write_to_oracle():\n",
        "    try:\n",
        "        # Create sample data\n",
        "        data = [(\"John\", 25), (\"Jane\", 30), (\"Bob\", 35)]\n",
        "        schema = StructType([\n",
        "            StructField(\"name\", StringType(), True),\n",
        "            StructField(\"age\", IntegerType(), True)\n",
        "        ])\n",
        "        \n",
        "        df = spark.createDataFrame(data, schema)\n",
        "        \n",
        "        # Write to Oracle\n",
        "        df.write \\\n",
        "            .format(\"jdbc\") \\\n",
        "            .option(\"url\", jdbc_url) \\\n",
        "            .option(\"user\", oracle_user) \\\n",
        "            .option(\"password\", oracle_password) \\\n",
        "            .option(\"driver\", \"oracle.jdbc.driver.OracleDriver\") \\\n",
        "            .option(\"dbtable\", \"sample_people\") \\\n",
        "            .mode(\"overwrite\") \\\n",
        "            .save()\n",
        "        \n",
        "        print(\"Data written to Oracle successfully!\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error writing to Oracle: {str(e)}\")\n",
        "\n",
        "# Example 3: Perform a complex operation\n",
        "def complex_operation():\n",
        "    try:\n",
        "        # Read data from Oracle\n",
        "        df = spark.read \\\n",
        "            .format(\"jdbc\") \\\n",
        "            .option(\"url\", jdbc_url) \\\n",
        "            .option(\"user\", oracle_user) \\\n",
        "            .option(\"password\", oracle_password) \\\n",
        "            .option(\"driver\", \"oracle.jdbc.driver.OracleDriver\") \\\n",
        "            .option(\"query\", \"SELECT * FROM sample_people\") \\\n",
        "            .load()\n",
        "        \n",
        "        # Perform some transformations\n",
        "        result = df.groupBy(\"age\").count()\n",
        "        \n",
        "        print(\"Age distribution:\")\n",
        "        result.show()\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error in complex operation: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting PySpark Oracle Demo...\")\n",
        "    \n",
        "    # Run examples\n",
        "    read_from_oracle()\n",
        "    write_to_oracle()\n",
        "    complex_operation()\n",
        "    \n",
        "    # Stop Spark session\n",
        "    spark.stop() "
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}